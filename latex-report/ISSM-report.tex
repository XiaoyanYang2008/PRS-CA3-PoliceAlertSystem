% Template for ICIP-2019 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx,titlesec}

    
% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}


% Title.
% ------
\title{ISSM report, Police Alert System}
%
% Single address.
% ---------------
\name{NG SIEW PHENG, TEA LEE SENG, YANG XIAOYAN	}
\address{Institute of Systems Science, National University of Singapore, Singapore 119615}

\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
% Briefly describe your problem statement and the proposed approach.

Singapore is a safe country. However, any gun shots become more dangerous in neighbourhood area, due to less awareness in public. It is critical to maintain safety here and automate alerting mechanism to Police will be time and life saving. 
We propose machine learning mechanism to understand background sound in Urban setup to identify gun shots. We apply techniques like 1D conv neural network, auto-encoder, LSTM, neural network on MFCC to understand which is good for recognizing gun shots in URBANSOUND8K DATASET.
 

\end{abstract}
%
\begin{keywords}
URBANSOUND8K DATASET, long short-term memory, auto encoder, mfcc, conv1D, MaxPooling1D, deep neural network, deep learning
\end{keywords}
%
\section{Introduction}
\label{sec:intro}
% Describe the problem you are working on and why it is important. 


Dangerous weapons can be a source of dangerous in a safe country.  Gun shots become more dangerous in neighbourhood area, due to less awareness in public. It is critical to maintain safety here and automate alerting mechanism to Police will be time and life saving. It is easpecially the case that police station may be far away from the incident area and they do not get alerted unless civilians reported it to them. Even with reports, the actual sound about the incident is lost and therefore losing original data.


% \begin{itemize}
%  \item The main report is provided in *.tex file
%  \item The reference is provided in *.bib file
%  \item The figures are provided as separate jpg/png files
% \end{itemize}


\section{Related work}

% Discuss published works or online references that relate to your project, such as \cite{adams1995hitchhiker}
% \cite{MikeSmalesSoundClassificationusingDeepLearning}

We download URBANSOUND8K DATASET from \cite{URBANSOUND8K-DATASET} for analysis and classification models training. URBANSOUND8K DATASET was processed for \cite{Salamon:UrbanSound:ACMMM:14} research.


We also refer to Ricky Kim's articles about UrbanSound Classification Part 1 \cite{RickyKimUrbanSoundClassificationPart1soundwavedigitalaudiosignal} and Part 2 \cite{RickyKimUrbanSoundClassificationPart2samplerateconversionLibrosa} for initial understanding of datasets. 

Mike's work \cite{MikeSmalesSoundClassificationusingDeepLearning} on 2d convolution deep neural network on MFCC also share us another direction on utilizing frequency domain representation for analysis. 


\section{Proposed approach}
\label{sec:proposed approach}
Based on the nature that all sounds wave files are 1 dimensional signals, sampling at different frequencies, we retrieved wave data via librosa library at default 22khz sampling rate.

We concatenates signals itself to 4 seconds long as signal feature.

We feed the signals to conv1d, auto-encoder, and LSTM networks for classification.

we also convert signals to mfcc representation, apply mean on each mfcc stream and 3 layers dense neural network for classification.

Please refers experimental results section for details.


\label{sec:experimental results}
\section{Data preprocessing and analysis}
URBANSOUND8K DATASET\cite{URBANSOUND8K-DATASET} contains 8732 labeled sounds of 10 classes:
air\_conditioner, car\_horn, children\_playing, dog\_bark, drilling, enginge\_idling, gun\_shot, jackhammer, siren, and street\_music.
The sounds are of various sampling rate as well as sampling rate. We utilize librose to convert sampling rate to 22kHz and mono channel. 

\begin{figure}[h]
	\centerline{\begin{tabular}{cc|c}
			\includegraphics[width=7cm]{pic/data-loading.png}
	\end{tabular}}
	\caption{sound data loading, multiprocessing.\label{figure1}}
\end{figure}

As for sound duration that's less than 4 seconds, we concatenates the sound itself until it fills up the 4 seconds duration.

\begin{figure}[h]
	\centerline{\begin{tabular}{cc|c}
			\includegraphics[width=7cm]{pic/self-repeatUntil4secs.png}
	\end{tabular}}
	\caption{self repeating to fill up to 4 seconds.\label{figure2}}
\end{figure}

We also plot and listen to a few gun shots and other sound files.
\begin{figure}[h]
	\centerline{\begin{tabular}{cc|c}
			\includegraphics[width=7cm]{pic/plotAndPlaySounds.png}
	\end{tabular}}
	\caption{Plot and listen some sound files.\label{figure3}}
\end{figure}


\section{Experimental results}

\subsection{Conv1D deep neural network classification}
We constructed a four layers of Convolutional Neural Networks model for the wave data. the input data is 1D array which has 89007 features.
\begin{figure}[!htb]
    \begin{tabular}{c}
        \includegraphics[width=8cm]{pic/CNN_Create.png}\\
    (Figure.model layers)
    \end{tabular}
\end{figure}
\begin{figure}[!htb]
    \begin{tabular}{c}
        \includegraphics[width=8cm]{pic/CNN_Sum.png}\\
    (Figure. model summary)
    \end{tabular}
\end{figure}
After data training and validation, the accuracy and the loss function showed training has good result but validation not.
\begin{figure}[!htb]
    \begin{tabular}{c}
        \includegraphics[width=7cm]{pic/CNN_Pm.png}\\
    (Figure. CNN accuracy score and confusion matrix)
    \end{tabular}
\end{figure}
We used a test data set did a prediction for the sounds classes, the result is 24.37\%. The gun shot prediction is 66.67\%.
\begin{figure}[!htb]
    \begin{tabular}{cc}
        \includegraphics[width=4cm]{pic/CNN_ACC.png}
        &\includegraphics[width=4cm]{pic/CNN_LOSS.PNG}\\
    (Figure.model accuracy)&(Figure.model loss)
    \end{tabular}
\end{figure}

Since our system is to check the dangerous sound (gun shot), we grouped non gun shot sounds as one class and gun shot as one class. Did another training for the data.
\begin{figure}[!htb]
    \begin{tabular}{cc}
        \includegraphics[width=4cm]{pic/CNN_ACC_V2.PNG}
        &\includegraphics[width=4cm]{pic/CNN_Loss_V2.PNG}\\
    (Figure.model accuracy)&(Figure.model loss)
    \end{tabular}
\end{figure}
We used the test data set did a prediction for the sounds classes, the result is 97.14\%, but the gun shot prediction is 57.63\%.
\begin{figure}[!htb]
    \begin{tabular}{c}
        \includegraphics[width=7cm]{pic/CNN_Pm_V2.PNG}\\
    (Figure. CNN accuracy score and confusion matrix)
    \end{tabular}
\end{figure}
The accuracy of CNN is not good, we switch to other models.

\subsection{Autoencoder anomaly detection}
Based on 4 seconds self-repeat sound, we construct autoencoder and train with sounds sample without gun shots. Below is the code snipet for the autoencoder network.

\begin{figure}[ht]
	\centerline{\begin{tabular}{c}
			\includegraphics[width=7cm]{pic/auto-encoder-network.png}
	\end{tabular}}
	\caption{Autoencoder network.\label{figure4}}
\end{figure}
\begin{figure}[ht]
	\centerline{\begin{tabular}{c}
			\includegraphics[width=7cm]{pic/autoencoder-training-summary.png}
	\end{tabular}}
	\caption{Autoencoder network training and its structure\label{figure5}}
\end{figure}

By training autoencoder network with non gun shots sound data, we hope that gun shots sound will be recognized as anomaly to the network. Due to 4 seconds and sampling rate of 22kHz, our data will be 1D arrary of 88.200k samples. From Fig. \ref{figure5}, layer1, which is the innermost layer of undercomplete autoencoder neural network, it has only 8 neurons.

The code to analyse performance of training data and gun shot(noise, test) anomaly detection is as below. 

\begin{figure}[ht]
	\centerline{\begin{tabular}{c}
			\includegraphics[width=7cm]{pic/autoencoded-8-31.png}
	\end{tabular}}
	\caption{Auto encoder performance analysis code snipet\label{figure6}}
\end{figure}
Based on the errors collected from network prediction on training data and gun shot data, we calculate mean and standard deviation, std. With 95\% confidence level as guideline, we set the threshold to mean+2*std, which is 62.17.

\newpage

\begin{figure}[ht]
	\centerline{\begin{tabular}{c}
			\includegraphics[width=7cm]{pic/autoencoder-8-31-result.png}
	\end{tabular}}
	\caption{Autoencoder performance analysis\label{figure7}}
\end{figure}

With threshold of 62.17 in Fig. \ref{figure7}, we found out that only 4.2\% of training data is anomaly, whereas gun shot data anomaly rate is about 30.48\% at 95\% confidence level. 

Though the performance is not amazing compared to other methods in later parts of experiements. It is interesting that autoencoder can detect anomaly even within its own training data. It is useful that when we don't have much labelled data but unsupervised learning like this, helps to point out anomaly.


We also notice another counter intuitive perspective about autoencoder. For neural network, more neurons tends to performance better.
\begin{figure}[ht]
	\centerline{\begin{tabular}{c}
			\includegraphics[width=7cm]{pic/autoencoder-800.png}
	\end{tabular}}
	\caption{Autoencoder with 800 innermost layer \label{figure8}}
\end{figure}
However, this is not the case for autoencoder. We configure 100x more neurons for innermost layer, and spend more times on compute. And here is the performance of the network,
\begin{figure}[ht]
	\centerline{\begin{tabular}{c}
			\includegraphics[width=7cm]{pic/autoencoder-800-performance.png}
	\end{tabular}}
	\caption{Performance of Autoencoder with 800 innermost layer \label{figure8}}
\end{figure}

The performance on gunshot anomaly detection is only 4.8\%, which is only 16\% of 8 neurons network. Therefore, more under-complete autoencoder network likely pressing the neural network to perform better.



\subsection{LSTM neural network classifcation}




\subsection{mfcc representation and neural network classification}





%\begin{equation}\label{equation block model}
%B_{r,c}=\sum\{f(i,j)|(i,j)\in \Omega_{r,c}\}.
%\end{equation}
%\begin{equation}\label{equation 1}
%\sum_{x}=a+b+\hat{c},
%\end{equation}

%An inline equation is $a+b=c$. An example of two-column figure is provided in Figure \ref{figure1}, and the single-column figures is provided in Figure \ref{figure2}.

%\begin{figure*}[tbh]\includegraphics[width=15cm]{iss.png}
%    \caption{Test figure (two-column).\label{figure1}}
%\end{figure*}


\begin{figure}[tbh]
    \centerline{\begin{tabular}{cc|c}
        \includegraphics[width=3cm]{iss.png}
        &\includegraphics[width=3cm]{iss.png}& text\\
    (a) & (b) & (c)
    \end{tabular}}
    \caption{Test figure (single column).\label{figureZZZ}}
\end{figure}

\begin{table}[tbh]
\caption{The performance comparison.}\label{table1} \centerline{
    \begin{tabular}{clc|r}
    \hline\hline
    Approach & Ref.  & Ref. \cite{URBANSOUND8K-DATASET} & Proposed approach\\
    Metric A & $0.8181$ & $0.9171$ & $0.9616$ \\\hline
    Metric B & $0.8236$ & $0.7654$ & $0.8615$ \\\hline
    \end{tabular}
    }
\end{table}

\section{Conclusions}
\label{sec:conclusions}

Summarize your key results. What are limitations of your approach? Suggest ideas for future extensions of your ideas.


\bibliographystyle{IEEEbib}
\bibliography{references}

\end{document}
